Ffjord: Free-form continuous dynamics for scalable reversible generative models; Invertible residual networks; Your classifier is secretly an energy based model and you should treat it like one; Backpropagation through the void: Optimizing control variates for black-box gradient estimation; Learning the Stein Discrepancy for Training and Evaluating Energy-Based Models without Sampling; Deep reinforcement learning and simulation as a path toward precision medicine; Oops i took a gradient: Scalable sampling for discrete distributions; Understanding the limitations of conditional generative models; Disentangling space and time in video with hierarchical variational auto-encoders; Continuous diffusion for categorical data; Reduce, reuse, recycle: Compositional generation with energy-based diffusion models and mcmc; Gradient-based optimization of neural network architecture; Joint energy-based models for semi-supervised classification; Score-based diffusion meets annealed importance sampling; Optimal design of stochastic DNA synthesis protocols based on generative sequence models; Self-conditioned embedding diffusion for text generation; No MCMC for me: Amortized samplers for fast and stable training of energy-based models; Annealed importance sampling meets score matching; Denoising diffusion samplers; No conditional models for me: Training joint ebms on mixed continuous and discrete data
