Shortcut learning in deep neural networks; Out-of-distribution generalization via risk extrapolation (rex); Invertible residual networks; Your classifier is secretly an energy based model and you should treat it like one; Why musical memory can be preserved in advanced Alzheimerâ€™s disease; i-RevNet: Deep Invertible Networks; Residual flows for invertible generative modeling; Flexibly fair representation learning by disentanglement; Environment inference for invariant learning; How to train your neural ODE: the world of Jacobian and kinetic regularization; Excessive invariance causes adversarial vulnerability; Fundamental tradeoffs between invariance and sensitivity to adversarial perturbations; Structured Receptive Fields in CNNs; Understanding and mitigating exploding inverses in invertible neural networks; Preventing gradient attenuation in lipschitz constrained convolutional networks; Learning the stein discrepancy for training and evaluating energy-based models without sampling; Understanding the Limitations of Conditional Generative Models; Dynamic steerable blocks in deep residual networks; Hierarchical Attribute CNNs; Joint energy-based models for semi-supervised classification
