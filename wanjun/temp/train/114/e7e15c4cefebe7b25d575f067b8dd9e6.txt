A global geometric framework for nonlinear dimensionality reduction; Human-level concept learning through probabilistic program induction; Building machines that learn and think like people; Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling; How to grow a mind: Statistics, structure, and abstraction; The large‚Äêscale structure of semantic networks: Statistical analyses and a model of semantic growth; Hierarchical topic models and the nested Chinese restaurant process; Topics in semantic representation.; Meta-learning for semi-supervised few-shot classification; Word learning as Bayesian inference.; Global versus local methods in nonlinear dimensionality reduction; Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation; Theory-based Bayesian models of inductive learning and reasoning; Deep convolutional inverse graphics network; Separating style and content with bilinear models; Causal inference in multisensory perception; Action understanding as inverse planning; Church: a language for generative models; One shot learning of simple visual concepts; Learning systems of concepts with an infinite relational model
