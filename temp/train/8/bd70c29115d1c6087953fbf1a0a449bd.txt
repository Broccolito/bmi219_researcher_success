Language models can learn complex molecular distributions; Neural message passing on high order paths; Mapping Gaussian process priors to Bayesian neural networks; Graph deconvolutional generation; Learning interpretable representations of entanglement in quantum optics experiments using deep generative models; Scalable Fragment-Based 3D Molecular Design with Reinforcement Learning; Learning quantum dynamics with latent neural ordinary differential equations; Characterizing and warping the function space of bayesian neural networks; Language models can generate molecules, materials, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files; Bayesian Variational Optimization for Combinatorial Spaces; Atom-by-atom protein generation and beyond with language models
